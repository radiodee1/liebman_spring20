\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Background/History of the Study}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Background}{2}{section.1.1}% 
\contentsline {section}{\numberline {1.2}Recurrent Neural Network Components}{2}{section.1.2}% 
\contentsline {subsection}{\numberline {1.2.1}Overview}{2}{subsection.1.2.1}% 
\contentsline {subsection}{\numberline {1.2.2}Gated Recurrent Unit}{3}{subsection.1.2.2}% 
\contentsline {section}{\numberline {1.3}Sequence to Sequence}{4}{section.1.3}% 
\contentsline {subsection}{\numberline {1.3.1}Word Embeddings}{5}{subsection.1.3.1}% 
\contentsline {subsection}{\numberline {1.3.2}Corpus}{6}{subsection.1.3.2}% 
\contentsline {subsection}{\numberline {1.3.3}Input Tokens}{7}{subsection.1.3.3}% 
\contentsline {subsection}{\numberline {1.3.4}Encoder}{7}{subsection.1.3.4}% 
\contentsline {subsection}{\numberline {1.3.5}Decoder}{8}{subsection.1.3.5}% 
\contentsline {subsection}{\numberline {1.3.6}Output Tokens}{9}{subsection.1.3.6}% 
\contentsline {subsection}{\numberline {1.3.7}Loss and Accuracy During Training}{10}{subsection.1.3.7}% 
\contentsline {subsection}{\numberline {1.3.8}Attention Mechanism}{11}{subsection.1.3.8}% 
\contentsline {subsection}{\numberline {1.3.9}Sequence to Sequence Chatbot}{12}{subsection.1.3.9}% 
\contentsline {chapter}{\numberline {2}Transformers and The Generative Pre-training Transformer 2}{14}{chapter.2}% 
\contentsline {section}{\numberline {2.1}Transformer and Attention}{15}{section.2.1}% 
\contentsline {subsection}{\numberline {2.1.1}Byte Pair Encoding}{15}{subsection.2.1.1}% 
\contentsline {subsection}{\numberline {2.1.2}Attention}{16}{subsection.2.1.2}% 
\contentsline {subsection}{\numberline {2.1.3}Scaled Dot-Product Attention}{16}{subsection.2.1.3}% 
\contentsline {subsection}{\numberline {2.1.4}Decoder}{19}{subsection.2.1.4}% 
\contentsline {subsection}{\numberline {2.1.5}Input - Positional Encoding}{22}{subsection.2.1.5}% 
\contentsline {subsection}{\numberline {2.1.6}Output - Feed Forward Network}{22}{subsection.2.1.6}% 
\contentsline {subsection}{\numberline {2.1.7}Visualization - Transformer}{22}{subsection.2.1.7}% 
\contentsline {section}{\numberline {2.2}The Generative Pre-training Transformer 2 Model}{23}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Pre-Training}{23}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}General}{24}{subsection.2.2.2}% 
\contentsline {subsection}{\numberline {2.2.3}Corpus}{25}{subsection.2.2.3}% 
\contentsline {subsection}{\numberline {2.2.4}Releases}{25}{subsection.2.2.4}% 
\contentsline {subsection}{\numberline {2.2.5}Application Details}{26}{subsection.2.2.5}% 
\contentsline {subsection}{\numberline {2.2.6}Visualization - GPT2}{27}{subsection.2.2.6}% 
\contentsline {chapter}{\numberline {3}Experiments}{28}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Approach to the Study}{29}{section.3.1}% 
\contentsline {section}{\numberline {3.2}Model Overview}{29}{section.3.2}% 
\contentsline {section}{\numberline {3.3}Setup}{30}{section.3.3}% 
\contentsline {subsection}{\numberline {3.3.1}Graphical Processing Unit vs. Central Processing Unit}{31}{subsection.3.3.1}% 
\contentsline {subsection}{\numberline {3.3.2}Raspberry Pi}{32}{subsection.3.3.2}% 
\contentsline {subsection}{\numberline {3.3.3}Tensorflow vs. Pytorch}{32}{subsection.3.3.3}% 
\contentsline {subsection}{\numberline {3.3.4}Speech and Speech To Text}{33}{subsection.3.3.4}% 
\contentsline {subsection}{\numberline {3.3.5}Corpus Considerations}{34}{subsection.3.3.5}% 
\contentsline {section}{\numberline {3.4}ARMv7 Build/Compile}{34}{section.3.4}% 
\contentsline {subsection}{\numberline {3.4.1}Pytorch `torch' Library 1.1.0 For ARMv7}{34}{subsection.3.4.1}% 
\contentsline {subsection}{\numberline {3.4.2}Pytorch `torch' Library 1.4.0 For ARMv7}{35}{subsection.3.4.2}% 
\contentsline {subsection}{\numberline {3.4.3}Docker Container `tensorflow-model-server' For ARMv7}{36}{subsection.3.4.3}% 
\contentsline {section}{\numberline {3.5}Experiments - Installations}{37}{section.3.5}% 
\contentsline {subsection}{\numberline {3.5.1}Chatbot - Gated Recurrent Unit Model}{38}{subsection.3.5.1}% 
\contentsline {subsection}{\numberline {3.5.2}Smart Speaker - Gated Recurrent Unit Model}{39}{subsection.3.5.2}% 
\contentsline {subsection}{\numberline {3.5.3}Chatbot - Transformer Model with Persona Corpus}{40}{subsection.3.5.3}% 
\contentsline {subsection}{\numberline {3.5.4}Smart Speaker - Transformer Model with Persona Corpus}{42}{subsection.3.5.4}% 
\contentsline {subsection}{\numberline {3.5.5}Chatbot - Transformer Model with Movie Corpus}{42}{subsection.3.5.5}% 
\contentsline {subsection}{\numberline {3.5.6}Smart Speaker - Transformer Model with Movie Corpus}{44}{subsection.3.5.6}% 
\contentsline {subsection}{\numberline {3.5.7}Chatbot - Generative Pre-training Transformer 2 Model}{45}{subsection.3.5.7}% 
\contentsline {subsubsection}{Context Experiment}{45}{section*.9}% 
\contentsline {subsubsection}{History Experiment}{46}{section*.10}% 
\contentsline {subsubsection}{Artificial Intelligence Markup Language Experiment}{46}{section*.11}% 
\contentsline {subsubsection}{Overall}{47}{section*.12}% 
\contentsline {subsection}{\numberline {3.5.8}Smart Speaker - Generative Pre-training Transformer 2 Model}{48}{subsection.3.5.8}% 
\contentsline {section}{\numberline {3.6}Observation}{49}{section.3.6}% 
\contentsline {subsection}{\numberline {3.6.1}GRU vs. Transformer}{49}{subsection.3.6.1}% 
\contentsline {subsection}{\numberline {3.6.2}Smaller Chatbot Learning}{50}{subsection.3.6.2}% 
\contentsline {subsection}{\numberline {3.6.3}Word Usage}{50}{subsection.3.6.3}% 
\contentsline {subsection}{\numberline {3.6.4}Sentence Usage}{52}{subsection.3.6.4}% 
\contentsline {section}{\numberline {3.7}Tests}{53}{section.3.7}% 
\contentsline {subsection}{\numberline {3.7.1}Turing Test}{53}{subsection.3.7.1}% 
\contentsline {subsection}{\numberline {3.7.2}Winograd Schema}{53}{subsection.3.7.2}% 
\contentsline {chapter}{\numberline {A}Further Installations}{55}{appendix.A}% 
\contentsline {section}{\numberline {A.1}Generative Pre-training Transformer 2 - Large Model}{55}{section.A.1}% 
\contentsline {subsection}{\numberline {A.1.1}Context Experiment}{55}{subsection.A.1.1}% 
\contentsline {subsection}{\numberline {A.1.2}History Experiment}{56}{subsection.A.1.2}% 
\contentsline {subsection}{\numberline {A.1.3}Artificial Intelligence Markup Language Experiment}{56}{subsection.A.1.3}% 
\contentsline {subsubsection}{User Name}{57}{section*.14}% 
\contentsline {subsubsection}{Internet Search Experiment}{58}{section*.15}% 
\contentsline {subsubsection}{Usage Example}{59}{section*.16}% 
\contentsline {chapter}{\numberline {B}Abbreviations}{60}{appendix.B}% 
