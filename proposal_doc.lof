\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Recurrent Neural Network}}{3}{figure.1.1}% 
\contentsline {figure}{\numberline {1.2}{\ignorespaces Word Embeddings}}{6}{figure.1.2}% 
\contentsline {figure}{\numberline {1.3}{\ignorespaces Sequence to Sequence Architecture}}{9}{figure.1.3}% 
\contentsline {figure}{\numberline {1.4}{\ignorespaces Loss and Accuracy}}{13}{figure.1.4}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Lowering Dimensionality}}{18}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Attention Output}}{19}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Matching Input and Output}}{20}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Transformer Encoder and Decoder Flow}}{21}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Transformer Encoder and Decoder}}{22}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces Visualized Attention}}{23}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces Generative Pre-training Transformer 2 }}{25}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces Visualized Attention GPT2}}{28}{figure.2.8}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Loss - Larger Transformer Model}}{44}{figure.3.1}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
