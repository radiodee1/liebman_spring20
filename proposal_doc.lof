\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Recurrent Neural Network}}{3}{figure.1.1}% 
\contentsline {figure}{\numberline {1.2}{\ignorespaces Word Embeddings}}{6}{figure.1.2}% 
\contentsline {figure}{\numberline {1.3}{\ignorespaces Sequence to Sequence Architecture}}{8}{figure.1.3}% 
\contentsline {figure}{\numberline {1.4}{\ignorespaces Loss and Accuracy}}{13}{figure.1.4}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Lowering Dimensionality}}{17}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Attention Output}}{18}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Matching Input and Output}}{19}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Transformer Encoder and Decoder Flow}}{20}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Transformer Encoder and Decoder}}{21}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces Visualized Attention}}{22}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces Generative Pre-training Transformer 2 }}{24}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces Visualized Attention GPT2}}{27}{figure.2.8}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Loss - Larger Transformer Model}}{43}{figure.3.1}% 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Word Usage}}{51}{figure.3.2}% 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Simple Word Usage}}{52}{figure.3.3}% 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Simple Sentence Usage}}{53}{figure.3.4}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
