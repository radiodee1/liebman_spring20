\BOOKMARK [0][-]{chapter.1}{Background/History of the Study}{}% 1
\BOOKMARK [1][-]{section.1.1}{Background}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Recurrent Neural Network Components}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{Sequence to Sequence}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{Loss and Accuracy}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.5}{Attention Mechanism}{chapter.1}% 6
\BOOKMARK [1][-]{section.1.6}{Sequence to Sequence Chatbot}{chapter.1}% 7
\BOOKMARK [0][-]{chapter.2}{Transformers and The Generative Pre-training Transformer 2}{}% 8
\BOOKMARK [1][-]{section.2.1}{Transformer and Attention}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.2}{The Generative Pre-training Transformer 2 Model}{chapter.2}% 10
\BOOKMARK [0][-]{chapter.3}{Experiments}{}% 11
\BOOKMARK [1][-]{section.3.1}{Approach to the Study}{chapter.3}% 12
\BOOKMARK [1][-]{section.3.2}{Model Overview}{chapter.3}% 13
\BOOKMARK [1][-]{section.3.3}{Setup}{chapter.3}% 14
\BOOKMARK [1][-]{section.3.4}{Graphical Processing Unit vs. Central Processing Unit}{chapter.3}% 15
\BOOKMARK [1][-]{section.3.5}{Raspberry Pi}{chapter.3}% 16
\BOOKMARK [1][-]{section.3.6}{Tensorflow vs. Pytorch}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.7}{Speech and Speech To Text}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.8}{ARMv7 Build/Compile}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.9}{Experiments - Installations}{chapter.3}% 20
\BOOKMARK [2][-]{subsection.3.9.1}{Chatbot - Gated Recurrent Unit Model}{section.3.9}% 21
\BOOKMARK [2][-]{subsection.3.9.2}{Smart Speaker - Gated Recurrent Unit Model}{section.3.9}% 22
\BOOKMARK [2][-]{subsection.3.9.3}{Chatbot - Transformer Model}{section.3.9}% 23
\BOOKMARK [2][-]{subsection.3.9.4}{Smart Speaker - Transformer Model}{section.3.9}% 24
\BOOKMARK [2][-]{subsection.3.9.5}{Chatbot - Generative Pre-training Transformer 2 Model}{section.3.9}% 25
\BOOKMARK [2][-]{subsection.3.9.6}{Smart Speaker - Generative Pre-training Transformer 2 Model}{section.3.9}% 26
\BOOKMARK [0][-]{appendix.A}{Abbreviations}{}% 27
