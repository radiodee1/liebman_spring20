\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\citation{DBLP:journals/corr/VinyalsL15}
\citation{2018Inkawhich}
\citation{Vaswani2017AttentionIA}
\citation{Danescu-Niculescu-Mizil+Lee:11a}
\citation{radford2019language}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Background/History of the Study}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Recurrent Neural Network and Transformer}{1}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Pre Trained Language Models}{1}{subsection.1.1.2}\protected@file@percent }
\citation{Wolf2019HuggingFacesTS}
\citation{2018Inkawhich}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Goals For This Thesis}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Recurrent Neural Network}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-recurrent}{{2}{4}{Recurrent Neural Network}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Recurrent Neural Network Components}{4}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Hidden Values}{4}{subsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Hidden Input}}{4}{figure.2.1}\protected@file@percent }
\newlabel{diagram-hidden}{{2.1}{4}{Hidden Input}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Simple RNN}{5}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Recurrent Neural Network}}{5}{figure.2.2}\protected@file@percent }
\newlabel{rnn-01}{{2.2}{5}{Recurrent Neural Network}{figure.2.2}{}}
\citation{2015Britz}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Gated Recurrent Unit}{6}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Sequence-to-Sequence and Translation}{7}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Word Embeddings}{7}{subsection.2.2.1}\protected@file@percent }
\citation{mikolov2013efficient}
\citation{pennington-etal-2014-glove}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Word Embeddings}}{8}{figure.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Corpus}{8}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Training and Evaluation}{8}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Input Tokens}{9}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Encoder}{9}{subsection.2.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Sequence-to-Sequence Architecture}}{10}{figure.2.4}\protected@file@percent }
\newlabel{diagram-s2s-overview}{{2.4}{10}{Sequence-to-Sequence Architecture}{figure.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Decoder}{10}{subsection.2.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Output Tokens}{11}{subsection.2.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.8}Loss and Accuracy During Training}{11}{subsection.2.2.8}\protected@file@percent }
\citation{2018Inkawhich}
\citation{DBLP:journals/corr/LuongPM15}
\citation{DBLP:journals/corr/LuongPM15}
\citation{2018Inkawhich}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.9}Attention Mechanism}{12}{subsection.2.2.9}\protected@file@percent }
\newlabel{section-gru-attention}{{2.2.9}{12}{Attention Mechanism}{subsection.2.2.9}{}}
\citation{DBLP:journals/corr/VinyalsL15}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.10}Batching Problems}{13}{subsection.2.2.10}\protected@file@percent }
\newlabel{section-gru-batching-problems}{{2.2.10}{13}{Batching Problems}{subsection.2.2.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.11}Exploding or Vanishing Gradients}{13}{subsection.2.2.11}\protected@file@percent }
\newlabel{section-gru-gradient-problems}{{2.2.11}{13}{Exploding or Vanishing Gradients}{subsection.2.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.12}Sequence-to-Sequence Chatbot}{13}{subsection.2.2.12}\protected@file@percent }
\citation{DBLP:journals/corr/VinyalsL15}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Loss and Accuracy}}{14}{figure.2.5}\protected@file@percent }
\@setckpt{chapters/chapter01}{
\setcounter{page}{15}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{2}
\setcounter{subsection}{12}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{0}
\setcounter{float@type}{8}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{23}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{section@level}{0}
\setcounter{lstlisting}{0}
}
