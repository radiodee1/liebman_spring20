\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Transformers and the Generative Pre-Training 2 Transformer}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter-transformer}{{3}{15}{Transformers and the Generative Pre-Training 2 Transformer}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Transformer and Attention}{15}{section.3.1}\protected@file@percent }
\newlabel{transformer-intro}{{3.1}{15}{Transformer and Attention}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Byte Pair Encoding}{15}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Attention}{15}{subsection.3.1.2}\protected@file@percent }
\citation{Vaswani2017AttentionIA}
\citation{Vaswani2017AttentionIA}
\citation{Vaswani2017AttentionIA}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Transformer Encoder and Decoder}}{16}{figure.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Encoder - Scaled Dot-Product Attention}{16}{subsection.3.1.3}\protected@file@percent }
\citation{Vaswani2017AttentionIA}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Lowering Dimensionality}}{17}{figure.3.2}\protected@file@percent }
\newlabel{diagram-mat-mult-01}{{3.2}{17}{Lowering Dimensionality}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Attention Output}}{18}{figure.3.3}\protected@file@percent }
\newlabel{attantion-7}{{3.3}{18}{Attention Output}{figure.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Matching Input and Output}}{19}{figure.3.4}\protected@file@percent }
\newlabel{attention-matching}{{3.4}{19}{Matching Input and Output}{figure.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Transformer Encoder and Decoder Flow}}{20}{figure.3.5}\protected@file@percent }
\newlabel{diagram-flow1}{{3.5}{20}{Transformer Encoder and Decoder Flow}{figure.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Encoder Attention Detail}}{21}{figure.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Decoder Attention I - ``Key'' and ``Value''}{21}{subsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Decoder Flow}}{22}{figure.3.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Decoder Attention Detail}}{23}{figure.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Decoder Attention II - ``Query''}{23}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Decoder Attention II - Masking}{23}{subsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Decoder Mask}}{24}{figure.3.9}\protected@file@percent }
\newlabel{diagram-mask-01}{{3.9}{24}{Decoder Mask}{figure.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Input - Positional Encoding}{24}{subsection.3.1.7}\protected@file@percent }
\citation{Vaswani2017AttentionIA}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.8}Output - Feed Forward Network}{25}{subsection.3.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.9}Visualization - Transformer}{25}{subsection.3.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Visualized Attention Transformer}}{25}{figure.3.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Generative Pre-Training 2 Model}{25}{section.3.2}\protected@file@percent }
\newlabel{pre-trining-2-model}{{3.2}{25}{The Generative Pre-Training 2 Model}{section.3.2}{}}
\citation{radford2018improving}
\citation{radford2018improving}
\citation{Vaswani2017AttentionIA}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Pre-Training}{26}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}General}{26}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Generative Pre-Training 2 }}{26}{figure.3.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Training}{27}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Inference}{27}{subsection.3.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Generative Pre-Training 2 Inference}}{28}{figure.3.12}\protected@file@percent }
\citation{radford2019language}
\citation{2019NVIDIAadlr}
\citation{radford2019language}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Corpus}{29}{subsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}Releases}{29}{subsection.3.2.6}\protected@file@percent }
\@writefile{lot}{\contentsline {section}{GPT2 Size Overview}{29}{subsection.3.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}Application Details}{29}{subsection.3.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.8}Visualization - GPT2}{30}{subsection.3.2.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Visualized Attention GPT2}}{30}{figure.3.13}\protected@file@percent }
\newlabel{diagram-vis04}{{3.13}{30}{Visualized Attention GPT2}{figure.3.13}{}}
\@setckpt{chapters/chapter03}{
\setcounter{page}{31}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{2}
\setcounter{subsection}{8}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{13}
\setcounter{table}{0}
\setcounter{float@type}{8}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{44}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{section@level}{0}
\setcounter{lstlisting}{0}
}
