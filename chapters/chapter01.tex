\section{Background}
We use Transformer style models and also a Recurrent Neural Network model to allow for meaningful comparison. There is also the Generative Pre-Training 2 Transformer. We explain RNN models below and Transformers in Chapter \ref{chapter-transformer}.

It is worth noting that with the appearance of the Transformer architecture some traditional technologies have become redundant or obsolete. This may be true of any model that uses Recurrent Neural Network components and also the traditional word vector embeddings.

\subsection{Recurrent Neural Network and Transformer}

In their paper Vinyals et al \cite{DBLP:journals/corr/VinyalsL15} discuss making a chatbot using a neural network configured for Sequence-to-Sequence Neural Machine Translation. An attempt to code our own Sequence-to-Sequence model was not very fruitful so instead we use code authored by Inkawhich et al \cite{2018Inkawhich}.

In their paper Vaswani et al \cite{Vaswani2017AttentionIA} discuss using the Transformer architecture for solving machine learning tasks. We train a transformer model as a chatbot.

In both of these experiments a common factor is the Movie Dialog Corpus that the models train on. The corpus comes from Danescu-Niculescu-Mizil et al \cite{Danescu-Niculescu-Mizil+Lee:11a}.

\subsection{Pre Trained Language Models}
Radford et al \cite{radford2019language} discuss the `Generative Pre-Training 2' (GPT2) neural network for Natural Language Processing (\ac{NLP}) tasks. The GPT2 model is based largely on the Transformer architecture. 

This is essentially a Language Model. The model is given a large section of text during training and it is asked to generate a single word or token to add to the end of the sample. During inference it does this over and over to complete a passage. This kind of model shows up in GPT2 and we use that trained model and some traditional programming techniques to generate text that naturally answers questions. Among all the models tested, this is the model that was found to be most comprehensive in execution.

Several chatbots are implemented, one with a GPT2 model using a program library from Wolf et al \cite{Wolf2019HuggingFacesTS} to run the model.


\section{Recurrent Neural Network Components}

%\subsection{Overview}
The goal behind Recurrent Neural Network (RNN) components is to detect patterns. Since understanding RNNs is important to GPT2 and Transformer models, it is discussed here. %Here we explore a simple \ac{RNN}.% first. 

\subsection{Hidden Values}
The term `Hidden Values' refers to the input or output of the RNN that is not exposed to the input tokens and is not converted to an output token. Hidden values are passed from one RNN component to another but are not passed to the output of the neural network. Additionally they are generated by an RNN element itself. Conceptually the input token from the input sentence is not passed to the Hidden input of any given RNN. They generally have the same dimensions as the input.

\begin{figure}[H]
	\begin{center}
		
		\includegraphics[scale=2.0]{diagram-hidden}
		
	\end{center}
	\caption[Hidden Input]{Hidden Input - Input and output connections for an RNN component.}
	\label{diagram-hidden}
	
\end{figure}


\subsection{Simple RNN}

Imagine using a string of words as input. This could be a sentence used for the input of a translation task with each word in the input called a token.

The simplest RNN unit has two inputs and two outputs. They can be arranged in patterns. In this example the input will be a sequence of data as stated above, and the Recurrent Neural Network will be a line of components of the same length as the data.

One input for each component is the hidden state output from the RNN to the left. Another input is the current token from the sequence that the component is encoding. One output is the generated hidden state, meant for the component to the right. The last output is the value that the Recurrent Neural Network outputs or surmises. 

\begin{figure}[H]
	\begin{center}
	
	\includegraphics[scale=0.5]{diagram-rnn01}
		
	\end{center}
	\caption[Recurrent Neural Network]{RNN - 1 and 2 are inputs, 3 is the output.}
	\label{rnn-01}

\end{figure}

In Figure \ref{rnn-01} the two inputs are labeled 1 and 2, and the single output does double duty as both the hidden state output and the value that the RNN outputs or surmises. This is labeled 3.

There are several designs for a RNN component. The inner workings of these components are what makes them different. In the example in the diagram the inner workings are very simple. Two paths, labeled as inputs, take data into the RNN. Their data is combined in the green circle. This combination is done with concatenation and simple feed forward neural network components. The output from the concatenation is passed through the other circle. This is a `tanh' activation operation that limits the output to values from -1 through 1. This `tanh' activation keeps the output within reasonable values. Finally the output is delivered outside the component to the program employing the RNN. In this diagram there is only one output. The single output would serve as both the hidden state output for that position in the encoder or decoder, and also the data output component for that position.



\subsection{Gated Recurrent Unit}
An implementation of a Recurrent Neural Network is the `Gated Recurrent Unit' (GRU). There are other varieties of RNN, most notably the Long Short Term Memory (LSTM) cell, not explored here. % We do not explore \ac{LSTM} cells here.

A \ac{GRU} has two inputs and two outputs. The formulas for a Gated Recurrent Unit, as outlined by Denny Britz in the website WILDML (Britz et al) \cite{2015Britz}, are as follows.

\begin{minipage}{5in}

$$ z =\sigma(x_tU^z + s_{t-1} W^z) $$  
$$ r =\sigma(x_t U^r +s_{t-1} W^r) $$  
$$ h = tanh(x_t U^h + (s_{t-1} \circ r) W^h) $$  
$$ s_t = (1 - z) \circ h + z \circ s_{t-1} $$  

\end{minipage}

\bigskip \bigskip

The GRU has two inputs and two outputs. It also has two internal gates. One internal gate is the `reset' gate. This one determines how much of the previous input is combined with the new value calculated by the mechanism of the GRU. It is denoted as `$r$' above. Another internal gate is the `update' gate. The update gate decides how much new information is to be included in gate computation. It is denoted as `$z$'.

Here `$ s_t $' is the symbol for the combined output. The two inputs are `$ x_t $' and `$ s_{t-1} $' . `$ x_t $' is hidden state input. `$ s_{t-1} $' is the regular input for the Recurrent Neural Network or Gated Recurrent Unit. Sigmoid activation is used on the two gates, using the symbol `$ \sigma(...) $' , while tanh activation is used to compute the hidden output. 

The dimension of the $U^z$, $U^r$ and $U^h$ matrices is the hidden unit size by the hidden unit size. $ x_t $ is a vector the size of the hidden unit. The $U$ values, along with $ W^z $, $ W^r $ and $ W^h $  are all simple matrices that allow the GRU to operate.

In the last line, the regular output is determined using the `dot' product which is denoted with a circle, along with an addition operation. In the two gate formulas (the first and second) the output is determined as the sum of two matrix multiplication operations passed through sigmoid activation. This produces values in the range of 0 to 1.

Under most programming circumstances the GRU is not implemented by the average programmer. The programmer employs a language like python and a programming library like Pytorch or Tensorflow. The library then implements the GRU and makes it easy for the programmer to use that implementation.

\section{Sequence-to-Sequence and Translation}

Translating text from one language to another has become a common task for computers. The Sequence-to-Sequence architecture is often used today for this purpose. %Here we explain how this works.

A naive approach to translation involves using a dictionary. Each key is encoded as a word from one language and the value for that key would be the translated word in the target language. Of course this doesn't work, because different languages not only have different words for the same thing, but they also have different sentence structures for what might be similar concepts.

A better approach for a computer is sequence-to-sequence translation. A description follows with a section at the end for how training works.

In this approach recurrent neural networks are used to obtain translation. Two recurrent neural network components are employed. One is responsible for the input language and the other for the output. 


\subsection{Word Embeddings}

Also employed are two vocabulary sets. One vocabulary is for the source language and another is for the target language. A table of word vectors the size of the input vocabulary is created and a maximum sentence length is picked. There is also a `hidden size', which is an important dimension in the model. In practice the hidden size could be 300 units and more for this kind of application.

Words are translated from strings to individual numbers from an input vocabulary dictionary. The dictionary only contains a single unique number for every word. Then the number is passed through an embedding structure. This turns the single number into a vector of numbers that is the same size as the RNN hidden dimension. Then, from that time on the model uses the vector instead of words.

The contents of the embedding unit is a table of numbers, all of the size of the RNN hidden dimension. The vectors are usually, but don\textquoteright t have to be, unique values. For each word in the dictionary there is a vector whose size is equal to the hidden dimension.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{diagram-embedding}
		
		
	\end{center}
	\caption[Word Embeddings]{Embeddings - Each word from a dictionary is converted to a vector of numbers.}
	

\end{figure}

The vectors can be initialized randomly or they can be filled with predetermined values. As the network trains, the embedding values can either be modified or frozen in place. Typically if the contents were initialized randomly the values would be trained. If the contents were filled with predetermined values, they are not trained or changed in any way. 

There are at this writing two main types of pretrained word embeddings. One is called \textquoteleft Word2Vec\textquoteright{} and one is called \textquoteleft GloVe.\textquoteright  

Word2Vec is short for \textquoteleft Word to Vector.\textquoteright{} (Mikolov et al.) \cite{mikolov2013efficient} GloVe is short for \textquoteleft Global Vector\textquoteright{} (Pennington et al.) \cite{pennington-etal-2014-glove} 


\subsection{Corpus}

A text must be prepared for training. A text corpus with source and target pairs is chosen. Sentences in the source corpus are paired with sentences with the same meaning in the target corpus. A sentence length restriction is observed and, for all sentences shorter than that length, a special `end-of-sequence' token is appended to all sequences. This restriction is applied in both languages.

\subsection{Training and Evaluation}
Our task is to train a Neural Network to translate a given input corpus. It is generally felt that the corpus should be divided into three parts. The largest part, possibly 80\%, is held for training. Then 10\% should go to what is called `validation' and 10\% should go to `testing'.

The training portion, obviously, is used during the training phase. The model can become familiar with training data and provide target data that leads one to believe that the model is learning well. This is similar to memorization. The model may see the same training data repeatedly and thereby learn how to answer a source with a target without learning the task of why it is giving a particular answer.

For this reason, during training, the validation set is used for statistical purposes. The actual training mechanism is halted and the validation set is run through the model. Loss is measured and compared to the loss found when training is enabled. Loss during validation is usually greater than during training. This is done periodically during what would otherwise be called training.

This is useful for tuning hyper-parameters, which are parameters that occur in the model. Repeatedly one trains, and as one does, one assesses the validation scores for clues on what to change in the hyper-parameters. 

When done one uses the final holdout set, the `test' set, to determine weather or not training has been successful. One must never train with the test or validation set.

\subsection{Input Tokens}

At this point, the model takes a word, translates it to an integer, and finds the vector in the word embedding table that represents that word. It does this for the first word and all subsequent words one by one. Then it gives the entire vector for a word to the GRU, one at a time. The GRU takes the word and passes it to inner components. It decides whether to return as output only the input or the input modified. This is what the Gated Recurrent Unit does internally.

The Gated Recurrent Unit takes as input two vectors. It processes the `input' vector and returns another vector. This could be exactly the same as the input but is usually somehow changed. The input vector and the output vector have the dimension of the `hidden size' mentioned above. Throughout the discussion of this model the hidden size will remain the same. The GRU also operates on two hidden states. One hidden state, a vector, is taken in and another hidden state, also a vector, is produced for output.

%We will describe the components in two groups. 
The input components, using the source language, are the encoder and the output components, using the target language, are the decoder.



\subsection{Encoder}

The input segments, composed of Gated Recurrent Units, take two input vectors and return two output vectors. One input is the vector from the embedding table. Another input vector is the previous hidden state. The hidden state is the same size as the input from the embedding table, but typically it comes from the previous Gated Recurrent Unit. The output vector is a hidden value for the Recurrent Unit to the right. %Refer to Figure \ref{diagram-s2s-overview}.

The very first Gated Recurrent Unit in the input encoder ignores the fact that the first word has no hidden value. It consumes the first word vector. Then it passes its output to the next Gated Recurrent Unit in the encoder. This GRU uses the output of the previous GRU as the hidden value. It also uses the vector for the second word. It passes its important information to the Gated Recurrent Unit to its right. This is repeated if needed. Then the last Gated Recurrent Unit in the encoder passes its hidden state to the output decoder.

A complicating detail is that although many GRUs are called for in the encoder, they all use the same set of weights and biases. For this reason only a single input Gated Recurrent Unit is used for all of the words in practice. 

%Outputs are calculated and then cycled and fed with the next word from the sentence in vector form to the input of the Gated Recurrent Unit. 

\begin{figure}[H]
	\begin{center}
		
		\includegraphics[scale=2]{diagram-nmt03}
		
	\end{center}
	\caption[Sequence-to-Sequence Architecture]{Seq2seq: The left represents an input sequence and the right represents the corresponding output. `sol' stands for `start-of-line'. `eol' stands for `end-of-line'}
	
	\label{diagram-s2s-overview}
	
\end{figure}


%%% move? %%%
In Figure \ref{diagram-s2s-overview} we generalize a sequence-to-sequence model. The left side of the diagram deals with the encoding of sentences. `Open the door' would be consecutive words in a sentence, and the rectangular blue nodes above those words are Recurrent Neural Network units. `Ouvre la porte' are outputs and in the right side of the diagram, the nodes represent the output RNN units. Between the input and the output, there is a corridor of information exactly the size of the RNN hidden vector. 

\subsection{Decoder}
The decoder is in charge of generating tokens that represent, in this case, the translation of the input to the output language. The output uses Gated Recurrent Unit segments also. The first hidden input for the first output cell is taken from the last hidden output of the last recursive unit of the input. It is important because it is the point where a great amount of data is passed from the encoder to the decoder. The connection at this point is said to carry the `thought vector.' Most of the information responsible for translating one language to another is passed at this point.

The hidden values from the input section are passed to the first output Gated Recurrent Unit. It outputs the values that are later converted to the first word of the translation. The first output Gated Recurrent Unit also has a hidden state. It passes the first word and the hidden state on to the second Gated Recurrent Unit to it's right.

The second Gated Recurrent Unit generates the second word and also its own hidden state. The second word is recorded and the word and the hidden state are passed on to the next Gated Recurrent Unit. This is repeated until a special `end-of-sequence' token is generated or until the number of tokens equals the maximum number allowed.



All of the information that the decoder uses for its output is present in the thought vector and is passed along the corridor from the encoder. %For this reason we refer to it as the thought vector. 
Aside from Attention Mechanisms, there are no other places where information is passed from the encoder to the decoder.

Making this vector larger by increasing the size of the hidden dimension allows for more information in the thought vector. Size also increases the time to train the network. The size must also match the dimension of the vectors in the GloVe or Word2Vec download, if one of those is used. 

Ultimately an exceedingly large hidden dimension does not improve the sequence-to-sequence model.

Again, in the Decoder, many GRU units are called for but they all share the same weights and biases. For this reason, a single GRU is employed for the entire decoder. The encoder and decoder are never the same unit.

\subsection{Output Tokens}
Each output is currently in the form of a vector. These vectors are long strings of floating point numbers, each one the dimensions of the `hidden size' mentioned above. They are converted to the dimensions of the output vocabulary, through matrix multiplication. Then they are processed in what is called a `softmax' function. This processing, along with an `arg-max' function, determines the index of the maximum value in the new vocabulary-sized vector. This index allows the program to find the corresponding word in the output vocabulary. This word is then used as the model output at that point in the output decoder.

Some computer models do language translation this way. Using `arg-max' is an example of a greedy approach to decoding. Another approach is `Beam Selection,' not discussed here. 



\subsection{Loss and Accuracy During Training}

At first the prediction from a model is not close to the desired output. The output is compared to the prediction and a `loss' is generated. `Loss' measures the difference between the predicted output and the target. A larger loss represents two values, prediction and target, that are further apart. 

Another metric is Accuracy, a numerical representation of the difference between the desired output and the generated prediction. It is a percentage of the time that the output is exactly correct.

Getting a prediction, running input data through a neural network, is forward-propagation. Training is a mathematical process involving back-propagation. Back-propagation identifies areas of the model weights that need to be modified in order to get the proper prediction in the future.

The derivative of the loss function is taken in order to back-propagate. The derivative is manipulated with the learning rate. A learning rate is required in these calculations. It is a small positive fraction. 

The original weight value is changed minutely. The amount changed with every backward propagation is dependent on the learning rate. The result is a set of adjusted weight matrices and a new loss. When these matrices are used later they allow for better predictions. 

To train the model this is done repeatedly with every source/target sentence pair. The model is changed and predictions start to match the target. The loss should decrease over time and the accuracy should increase.

%There are several numerical metrics that are recorded during training to measure success. The loss is a mathematical calculation of the difference between the model's output and the predicted value. Loss is an important metric as is accuracy. Accuracy is a mathematical calculation of the percentage of times the answer is right. 


\subsection{Attention Mechanism}

\label{section-gru-attention}

Attention Mechanisms are used by sequence-to-sequence models to transfer more information from the encoder to the decoder. The encoder imparts information to the decoder only at the `thought vector.' Attention helps the encoder tell the decoder which word is more important. This stressing of a vector by the model is the attention mechanism attending to one output.

A simple attention mechanism is used in the Sequence-to-Sequence model by Inkawhich et al. \cite{2018Inkawhich} The concept for this attention comes from Luong et al. \cite{DBLP:journals/corr/LuongPM15}

Luong et al \cite{DBLP:journals/corr/LuongPM15} are interested in three kinds of calculation for their attention mechanisms. These methods use slowly increasing levels of complication. First they propose a method that uses the dot-product. Then they propose a method that uses a field of weights. Finally they use a method that uses concatenation, along with a field of weights and a pass through a `tanh' activation layer.

$$
\boldmath
score(h_t^ \text{,} \bar{h}_s) =
\begin{cases}
    h_t^\intercal \bar{h}_s & \text{dot} \\
	h_t^\intercal W_a \bar{h}_s & \text{general} \\
	v_a^\intercal \text{tanh}(W_a [h_t ; \bar{h}_s] ) & \text{concat}
\end{cases}
\unboldmath
$$

Here $h_t$ is the symbol for the output of the current decoder and $\bar{h}_s $ is the symbol for another output taken from the input encoder. This is the entire set of encoder states. $h_t^\intercal$ stands for $h_t$ transposed. Inkawhich et al \cite{2018Inkawhich} uses the `dot' variety.

The formula is used after the decoder Gated Recurrent Unit calculates it's hidden state. It is below.

$$ 
\boldmath
\mathlarger{ \mathlarger{
score = h_t^\intercal \bar{h}_s 
} }
\unboldmath
$$ 

The output of the current decoder is transposed. It is multiplied by the hidden value from the entire set of encoder states. Later it is multiplied by the Gated Recurrent Unit decoder output, and passed through a `tanh' activation layer. It becomes the decoder output.

\subsection{Batching Problems}

\label{section-gru-batching-problems}

There are some general batching problems with using Recurrent Neural Network components.

If a batch of data is to be cycled through a recurrent component, it should go through all the components at once.  

%We want this to happen for whole batches at a time.

In Neural Machine Translation the data has to be processed one batch at a time. The data is passed to the first RNN. Only then it can be passed to the next RNN. A single GRU is used in this example for all words in the encoder, while another GRU is used in the decoder. These GRUs can not process the subsequent batches all at once. It must be done sequentially creating a bottleneck. 

%They have to wait for the previous batch to be done. This bottleneck has to do with how the RNN is used. 

These sorts of bottlenecks are found in Neural Machine Translation based on recurrent elements.

\subsection{Exploding or Vanishing Gradients}

\label{section-gru-gradient-problems}

There are some specific problems that affect gradients in Recurrent Neural Network components.

Data that begins with a floating point value above 1.0, when multiplied with weights with  values above 1.0, will return values above 1.0. The same RNN component is used for every position in the encoder or decoder. Some values will tend to infinity. This is called an exploding gradient. 


The reverse is true. When a number starts out as a floating point below 1.0, and is multiplied with RNN weights below 1.0, it will tend to a value of zero. This is called a vanishing gradient.


Gradients in an RNN can be unstable. RNN input and output lengths need to be limited to a small number. In our examples we use a limit of 10.

\subsection{Sequence-to-Sequence Chatbot}

Vinyals et al \cite{DBLP:journals/corr/VinyalsL15} make an interesting proposition. It is possible to make a Neural Conversational Model by constructing a Sequence-to-Sequence model. Instead of using two corpus from different languages, a single language is used for both source and target.

Chatbots have for a long time been constructed using \ac{AIML}. AIML, (Artificial Intelligence Markup Language) requires hand coding individual rules for every input and response. A Neural Conversational Model would not use those rules.

To create such a model, more is required than a single input and output language. There must be a relationship between the source and the target permitting a question and answer paradigm. Finding a corpus like this can be difficult.

It would be easy to duplicate the input source material in the target corpus, producing auto-encoding. The model would learn to repeat everything that was given to it in its output. Though the model learns a task, it is not the preferred task. Conversations, on the other hand, supply that relationship. 

Vinyals et al \cite{DBLP:journals/corr/VinyalsL15} use a movie transcript data set. Essentially they take movie dialogue and break it into sentences. Consecutive sentences can be divided into source and target. Each sentence is a source and the sentence that follows it would be the target for that pair. 

Training for this model is relatively straight forward, however the accuracy does not increase. Although the loss decreases, the accuracy is unimportant. %The loss goes down but the accuracy does not go up.

\begin{figure}[H]
	\begin{center}
	
	\includegraphics[scale=0.5]{Figure_1}
		
\end{center}
	\caption[Loss and Accuracy]{Loss and Accuracy: Loss is above and accuracy is below.}
	

\end{figure}

This is because the source and target do not have the same meaning. The model does learn the task at hand but during training accuracy must be ignored. Success is usually measured by the accuracy of the holdout test set. Here success is measured with the subjective examination of the trained model.

If the answers are considered satisfactory the training was a success. 

